<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Research Portfolio</title>
<link rel="stylesheet" type="text/css" href="css/styles.css">
<link rel="stylesheet" type="text/css" href="css/styles-class.css">
</head>

<body class="research-portfolio">

<!---->
<section>
  <div>
  </div>
  <div>
    <nav class="desktopOnly" style="padding-bottom: 20px;"> <a href="index.html" style="color: magenta; text-decoration: none;">Practical&nbsp;Resolution</a> &bull; <a href="#" style="color: magenta; text-decoration: none;">Critical&nbsp;Rationale</a> &bull; <a href="#" style="color: magenta; text-decoration: none;">Critical&nbsp;Context&nbsp;Paper</a> &bull; <a href="#" style="color: magenta; text-decoration: none;" class="active">Research&nbsp;Portfolio</a> </nav>
    <h1 style="color: magenta" class="h1ToH2OnMobile">Research Portfolio</h1>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title"> About this page </p>
  </div>
  <div>
    <p> What is documented in the research portfolio?</p>
    Relevant supporting developmental materials of Glitch Room &horbar; my MA Graphic Media Design major project at London College of Communication, University of the Arts London (UAL) in 2019.<br>
    <p>Why is it presented as a webpage? </p>
    1 To be cohesive with other parts of the project. <br>
    2 To enable live demonstration of past experiments inside this document, as they are only executable within a browser. <br>
    <p>Why is it mainly constructed by questions and answers?</p>
    1 For myself to be reflective by answering the questions. <br>
    2 To make it more engaging for the reader by raising curiosity with questions. <br>
    3 To make the contents easy to navigate through. <br>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Pattern as subject</p>
  </div>
  <div>
    <p>Why was pattern chosen as my research subject?</p>
    To fulfil my wish of exploring more visual-oriented areas rather than social-related topics. <br>
    <p>What experiments did I do?</p>
    1 The Letter Evolution: an experiment which aims at exploring the usage and effect of pattern making techniques on typographic design. <br>
    <div class="grid3">
      <img src="img/leb2.jpg" alt="">
      <img src="img/leb3.jpg" alt="">
      <img src="img/leb4.jpg" alt="">
    </div>
    <h6>&#8679; Example spreads of ‘The Letter Evolution’ by Nora Zhao (2019).</h6>
    2 Emotional Words: an experiment which explores the meaning and typographic pattern by highlighting and isolating enclosed space in written words. <br>
    <div class="grid2">
      <img src="img/ew1.jpg" alt="">
      <img src="img/ew2.jpg" alt="">
    </div>
    <h6>&#8679; Cover and an example spread of ‘Emotional Words’ by Nora Zhao (2019).</h6>
    3 Google Translate: an experiment which aims to visualise the influence of machine translation by showing a piece of sample text. <br>
    <div class="grid4">
      <img src="img/gt1.jpg" alt="">
      <img src="img/gt2.jpg" alt="">
      <img src="img/gt3.jpg" alt="">
      <img src="img/gt4.jpg" alt="">
    </div>
    <h6>&#8679; Cover and example spreads of ‘Google Translate’ by Nora Zhao (2019).</h6>
    <p>How do I evaluate these experiments? </p>
    1 Strength: explorations of pattern from different aspects. <br>
    2 Weakness: limited depth of investigation on pattern, and lack of iterations due to frequent change of directions. <br>
    <p>How to improve it? </p>
    To zoom down area of intended investigation and find a focus. <br>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Unique pattern as focus</p>
  </div>
  <div>
    <p>What was chosen as the focus?</p>
    Mass-produced unique patterns. <br>
    <p>What informed it?</p>
    Creative Review Annual 2019: each copy comes with a unique cover design created by Alex Trochut (<a href="https://www.creativereview.co.uk/one-of-a-kind-how-our-unique-annual-covers-were-created/">more info</a>). <br>
    <div class="grid4">
      <img src="img/cr1.jpg" alt="">
      <img src="img/cr2.jpg" alt="">
      <img src="img/cr3.jpg" alt="">
      <img src="img/cr4.jpg" alt="">
    </div>
    <h6>&#8679; Selected covers of 'Creative Review Annual 2019' by Alex Trochut (2019).</h6>
The appeal of this project is that it doesn’t aim at making one specific design. Instead, by making use of a generative tool, the designer was able to create unique design pieces. The results, as well as the approach, is stimulating. <br>
    <p> What was used as the generator of these variations? </p>
    HP Mosaic: a software which takes vector-based seed files as input and generates a set number of different output by random scaling, trans-positioning and rotating. <br>
    <div class="grid1">
      <img src="img/hp.jpg" alt="">
    </div>
    <h6>&#8679; Illustrated mechanism of HP Mosiac. Image by HP (2018). </h6>
    <p>What are the limitations of this software?</p>
    1 The options offered are limited. <br>
    2 The results, directly extracted from the already made designs, are more or less expected. <br>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Coding as tool</p>
  </div>
  <div>
    <p>What tool should be adopted for my project?</p>
    Coding: through writing code manually, I may build an executable program in which underlying computing tasks are constructed from my specific design needs.<br>
    <p>Why?</p>
    1 To break the restrictions set by ready-made design software. <br>
    2 To work directly with the medium which constructs digital design output. <br>
    3 Most importantly, to learn to code through practice and develop it as a skill to improve my competitiveness in the future. <br>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Z-fighting as technique</p>
  </div>
  <div>
    <p> What experiment did I do? </p>
    Mouse XY: an experiment in which the construction of pattern is made viable through mouse movement. <br>
    Hover over your mouse to draw. Double click to reset current canvas. Right click to save current image. <br>
    A JavaScript library called p5.js is used to create the canvases (<a href="https://p5js.org/">more info</a>).<br>
    <div class="grid2" style="grid-gap: 8px;">
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/p5-1.html" style="border:none; position:absolute; top:0; left:0; height:100%; width:100%;"> </iframe>
      </div>
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/p5-2.html" style="border:none; position:absolute; top:0; left:0; height:100%; width:100%;"> </iframe>
      </div>
    </div>
    <h6>&#8679; Example canvases of 'Mouse XY' by Nora Zhao (2019). </h6>
    <div class="grid4">
      <img src="img/p1.jpg" alt="">
      <img src="img/p2.jpg" alt="">
      <img src="img/p3.jpg" alt="">
      <img src="img/p4.jpg" alt="">
    </div>
    <h6>&#8679; Example output of 'Mouse XY' by Nora Zhao (2019). </h6>
    <p>How do I evaluate this experiment?</p>
    1 Strength: it’s responsive and playful. <br>
    2 Weakness: it’s highly reliant on manual input. Therefore, output quality may vary depending on the skill of the ‘painter’ and effort put in ‘painting’ the picture. <br>
    <p> How to solve it? </p>
    To build a program which functions automatically (generative). <br>
    <p>What demonstrated its viability?</p>
    Distinction Machine: a project by Kim Albrecht which explores computational behaviour under ambiguous situations. Geometries of different colours are positioned at the same location to produce pattern (<a href="https://distinctionmachine.kimalbrecht.com/">more info</a>).<br>
    <div class="grid1">
      <img src="img/dm2.jpg" alt="">
    </div>
    <h6>&#8679; Models of 'Distinction Machine' by Kim Albrecht (2019). </h6>
    <p>What technique was used to generate its dynamic output?</p>
    Z-fighting: a phenomenon in 3D rendering which occurs when two or more layers are positioned in identical or proximate positions. The colours ‘fight’ with each other to be shown on screen pixels and result in a flickering rasterisation effect. <br>
    <p>What coding tool was used to construct these scenes?</p>
    Three.js: a JavaScript library for creating and displaying animated 3D computer graphics in web browsers (<a href="https://threejs.org/">more info</a>). <br>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title"> Model building </p>
  </div>
  <div>
    <p>What experiment did I do? </p>
    Fighting Patterns: an experiment which generates pattern from a scene of z-fighting, in which the most straightforward geometric surface, flat plane, is used. <br>
    <div class="grid4">
      <div class="image-container">
        <img src="img/fp1.png" alt="">
        <div class="top-left-text">
          <h6>Front facing (1)</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/fp2.png" alt="">
        <div class="top-left-text">
          <h6>Front facing (2)</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/fp3.png" alt="">
        <div class="top-left-text">
          <h6>Tilted angle (1)</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/fp4.png" alt="">
        <div class="top-left-text">
          <h6>Tilted angle (2)</h6>
        </div>
      </div>
    </div>
    <h6>&#8679; Example output of 'Fighting Patterns' by Nora Zhao (2019).</h6>
    <div class="grid1">
      <img src="img/fw.png" alt="">
    </div>
    <h6>&#8679; Framework diagram of 'Fighting Patterns' by Nora Zhao (2019).</h6>
    <p>What did I find out? </p>
    Generated images may vary while the planes are tilted to different angles. <br>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Behaviour investigation</p>
  </div>
  <div>
    <p>What to be done next?</p>
    An investigation of z-fighting behaviour with the method of controlled experiments in which everything is held constant except for one variable. <br>
    <p>What are the findings?</p>
    Changes of camera position and plane rotation angle on x and y axes may result in different appearances of generated images. <br>
    <div class="grid3">
      <div class="image-container">
        <img src="img/zi1.png" alt="">
        <div class="top-left-text">
          <h6>Camera position on z axis: 1</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/zi2.png" alt="">
        <div class="top-left-text">
          <h6>Camera position on z axis: 0.8</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/zi3.png" alt="">
        <div class="top-left-text">
          <h6>Camera position on z axis: 0.2</h6>
        </div>
      </div>
    </div>
    <h6>&#8679; Example test results of camera positions on z axis by Nora Zhao (2019).</h6>
    <div class="grid3">
      <div class="image-container">
        <img src="img/zi4.png" alt="">
        <div class="top-left-text">
          <h6>Plane rotation: on both x and y axes</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/zi5.png" alt="">
        <div class="top-left-text">
          <h6>Plane rotation: on x axis only</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/zi6.png" alt="">
        <div class="top-left-text">
          <h6>Plane rotation: on y axis only</h6>
        </div>
      </div>
    </div>
    <h6>&#8679; Example test results of plane rotation combinations on x and y axes by Nora Zhao (2019).</h6>
    <div class="grid3">
      <div class="image-container">
        <img src="img/zi7.png" alt="">
        <div class="top-left-text">
          <h6>Plane rotation on x axis: 0.09</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/zi8.png" alt="">
        <div class="top-left-text">
          <h6>Plane rotation on x axis: 0.54</h6>
        </div>
      </div>
      <div class="image-container">
        <img src="img/zi9.png" alt="">
        <div class="top-left-text">
          <h6>Plane rotation on x axis: 0.74</h6>
        </div>
      </div>
    </div>
    <h6>&#8679; Example test results of plane rotations on x axis by Nora Zhao (2019). Similar situations occur with rotation on y axis. </h6>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Interaction</p>
  </div>
  <div>
    <p> How to make the findings accessible? </p>
    To add controls of these variables to enable the generation of various result sets. <br>
    <p>What other features were added? </p>
    1 Colour adjustments option: to allow setting up colours of personal preferences; <br>
    2 Random appearances: to create varied results upon each visit (or refreshment of the page) by combining randomly generated colour, plane rotation and camera position values; <br>
    3 Screenshot function: to offer a way of preserving generated results. <br>
    <p>What is the result of this experiment?</p>
    Configurable Pattern: a canvas in which an interactive control panel is implemented for customisable generation of z-fighting patterns. <br>
    Use the control panel or press refresh button to generate new looks. <br>
    <div class="grid1">
      <div style="position:relative; padding-top:70%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/pattern-3.html"> </iframe>
      </div>
    </div>
    <h6>&#8679; 'Configurable Pattern' by Nora Zhao (2019).</h6>
    <div class="grid5" style="grid-gap: 8px;">
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/pattern-2.html"> </iframe>
      </div>
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/pattern-2.html"> </iframe>
      </div>
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/pattern-2.html"> </iframe>
      </div>
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/pattern-2.html"> </iframe>
      </div>
      <div style="position:relative; padding-top:100%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/pattern-2.html"> </iframe>
      </div>
    </div>
    <h6>&#8679; Side by side display of 'Configurable Pattern' by Nora Zhao (2019).</h6>
    <p>Is there another variation of this experiment?</p>
    Yes. To add a focal point in the canvas, I also created a version with a circle in the middle. <br>
    Its colour, size, and location can be adjustable through the control panel. Alternatively, the circle can be dismissed through setting its scale to 0. <br>
    Additionally, from generated images, postcards were printed to materialise the artefacts.
    <div class="grid2" style="grid-row-gap: 8px;">
      <div style="position:relative; padding-top:50%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/dot.html"> </iframe>
      </div>
      <img src="img/dot.jpg" alt="">
    </div>
        <h6>&#8679; Live demonstration and printed postcards of 'Drop the Dot' by Nora Zhao (2019).</h6>

  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Sensor Data</p>
  </div>
  <div>
    <p>What can be explored further?</p>
    Organic ways of interaction. <br>
    <p>What primary research facilitated this thought?</p>
    At ‘The Shift’ exhibition, one of Rafaël Rozendaal’s websites (<a href="http://www.nosquito.biz/">source</a>) was transformed into an installation: when the visitor moves in the room, the sound of a mosquito will be played. Otherwise, the place stays silent (<a href="https://www.youtube.com/watch?v=6Zx1lRdhego">more info</a>). This straightforward but playful example demonstrates that the interaction between the user and artwork can be more responsive and organic. <br>
    Currently, my project only allows users to adjust the variables manually. However, ways of interaction can be further explored. In spite that a digital device is used to generated and presented the artwork, there can still be ways of bringing in external factors. <br>
    <div class="grid3">
      <img src="img/mos1.jpg" alt="">
      <img src="img/mos2.jpg" alt="">
      <video width="100%" controls  style="border:1px solid white;">
        <source src="img/mos3.mp4" type="video/mp4">
        Your browser does not support the video tag. </video>
    </div>
    <h6>&#8679; ‘The Shift’ solo show at W139 Amsterdam by Rafaël Rozendaal (2011). </h6>
    <p>How?</p>
    To reconsider the system’s input methods and parameters. <br>
    To be specific, environment-related factors, such as sound, light and movement can be turned into data by sensors and be utilised as automatic and continuous input of the image generating system. <br>
    <p>How to collect data?</p>
    From 'Plant-to-Plant Protocol' (a Supra Systems Studio workshop), I studied the basics of data transmission within the scope of physical computing in practice. This experience has informed me of the viability of using physical computing to collect and transport data from sensors to my image generation system. <br>
    <div class="flex">
      <div style="flex: calc(2000/2828);">
        <img src="img/pc1.jpg" alt="">
      </div>
      <div style="flex: calc(2016/1352);">
        <img src="img/pc5.jpg" alt="">
      </div>
      <div style="flex: calc(1430/948);">
        <img src="img/pc6.jpg" alt="">
      </div>
      <div style="flex: calc(1080/1080);">
        <img src="img/pc3.jpg" alt="">
      </div>
      <div style="flex: calc(1500/2000);">
        <img src="img/pc7.jpg" alt="">
      </div>
    </div>
    <h6>&#8679; Poster, the workshop and field device installation of 'Plant-to-Plant Protocol' (2019).</h6>
    With further research and technical support from the creative technology lab in LCC, I managed to connect the sound and light sensor to my model for data input. <br>
    <p>How to use the data as input of my experiment?</p>
    Since data collected by the sensors are mathematical values, it becomes a matter of using the numbers to influence components of the model: <br>
    1 Light: to change the brightness of colours because of their strong visual associations.<br>
    2 Sound: to control the scale of the model, so that the model has an approximate effect of sound visualisation and becomes a bridge which links hearing and sight senses. <br>
    <p>Why is sphere used in this experiment?</p>
    1 To add a sense of depth in space. <br>
    2 for extended flexibility: to have rotation along all x, y and z axes. <br>
    3 To create patterns which look distinct from the previous experiment (due to sphere’s unique structure). <br>
    <p>What else can be added in the system?</p>
    Gradual colour change: to enhance the dynamics of the generated visual results in such a way even when the data input doesn't trigger noticeable variations of the model, new colour combinations are still being formulated every moment. <br>
    <p>What is the result of this experiment?</p>
    Reactive Sphere: an automatically functioning responsive sphere model which produces bespoke pattern according to the combination of inner and outer factors. <br>
    <div class="grid3">
      <img src="img/sensor1.jpg" alt="">
      <img src="img/sensor4.jpg" alt="">
      <img src="img/sensor2.jpg" alt="">
    </div>
    <h6>&#8679; Components sensors and installation view of 'Reactive Sphere' in 'GMD Work in Progress' show by Nora Zhao (2019). </h6>
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx sol lewitt
    <div class="flex">
      <div style="flex: calc(1248/1403);">
        <img src="img/wd1.png" alt="">
      </div>
      <div style="flex: calc(1847/1270);">
        <img src="img/wd2.png" alt="">
      </div>
    </div>
    <h6>&#8679; Installation view of 'Focus: Sol LeWitt' exhibition: 'Wall Drawing #260 (1975)'. Photograph by Thomas Griesel (2008-2009). </h6>
  </div>
</section>

<!---->
<section>
  <div>
    <p class="left-title">Weather Data</p>
  </div>
  <div>
    <p>Is there any other data suitable for my project?</p>
    Zooming out of the environment near us and thinking bigger, there are also 'activities' of the mother nature that can be used as numeric input. <br>
    <p>What primary research facilitated this idea?</p>
    To reflect global diversity, D&AD's 2013 Annual cover, designed by Fleur Isbell, displayed 196 code generated illustrations from meta and location data for each country in the world (<a href=" https://fleur.isbell.net/portfolio/page01.html ">more info</a>). <br>
    <div class="grid3">
      <img src="img/dad1.jpg" alt="">
      <img src="img/dad2.jpg" alt="">
      <img src="img/dad3.jpg" alt="">
    </div>
    <h6>&#8679; 'D&AD Annual 2013 – Global Horizons' by Fleur Isbell (2013).</h6>
    This project demonstrated a viable way of using location-related data for automated visual generation. Similarly, weather data can be also be utilised in my project as it is not only dynamic but also relevant to our daily life. <br>

    <p>Where can I obtain the data? </p>
    Online database: for my project, the weather data is fetched from 'OpenWeather' (<a href=" https://openweathermap.org/">more info</a>). <br>
    <p>What is the result of this experiment?</p>
    City Sphere: a system which takes live weather data of designated city and generates corresponding model upon request.<br>
    <div class="grid1">
  <div style="position:relative; padding-top:70%; overflow:auto; border:1px solid white;">
        <iframe src="experiment/city-sphere.html"> </iframe>
      </div>
</div>
    <h6>&#8679; 'City Sphere' by Nora Zhao (2019).</h6>
    <div class="grid1">
    <img src="img/city.png" alt=""></div>
        <h6>&#8679; Output stills from 'City Sphere' at 18:35, 07 November 2019. Image by Nora Zhao (2019).</h6>

    <p>What can be further explored?</p>
If data from different cities are applied to the system, a series of results can be generated and presented  simultaneously. The form of this experiment may be altered for installation. <br>
    <p>What primary research encouraged this idea?</p>
   Prismatica: an installation created by RAW Design to engage visitors and invoke a feeling or mood from day to night. It consists of 50 prisms that glimmer under natural light by day and provide atmospheric lighting by night (<a href="https://www.rawdesign.ca/projects/prismatica/">more info</a>).<br>

    
    <div class="grid2">

      <img src="img/pri5.jpg" alt="">      <img src="img/pri6.jpg" alt="">
    </div>
        <h6>&#8679; 'Prismatica' by RAW Design (2015).</h6>
        This project differs from mine because the natural lighting, rather than live data, causes changes here. However, its quantitative approach and tangibility of physical objects are worth considering. <br>
    Specifically, it can be a number of spheres hanging in an exhibition room and have the generated moving image shown on their surfaces with the method of projection mapping. In this way, a physical space is created where various dynamic 3-dimensional artefacts can be viewed simultaneously. <br>
  </div>
</section>

<!---->
<section>
  <div>
    1
  </div>
  <div>
    2
  </div>
</section>

<!---->
<section>
  <div>
    1
  </div>
  <div>
    2
  </div>
</section>
</body>
</html>
